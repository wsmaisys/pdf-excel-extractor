# ğŸ“Š PDF Excel Extractor

> ğŸ¤– AI-Powered Document Structuring & Data Extraction System
>
> Production-ready AI agent that extracts structured data from unstructured PDF documents using LLM-powered semantic analysis.

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.100+-green.svg)](https://fastapi.tiangolo.com/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

[![Cloud Run](https://img.shields.io/badge/Cloud%20Run-Live-blue?logo=googlecloud)](https://pdf-excel-extractor-912303930048.us-central1.run.app/)

---

## ğŸŒŸ Key Features

âœ¨ **Dynamic Schema Detection** - LLM analyzes documents to determine relevant fields (no hardcoded schema)  
ğŸ¯ **Semantic Understanding** - Converts narrative text PDFs into structured Excel spreadsheets  
ğŸ“ˆ **Quality Assurance** - Built-in evaluation with BLEU scores and coverage metrics  
âš¡ **Batch Processing** - Efficient single LLM call for all data extraction  
ğŸ” **PDF Type Detection** - Automatically identifies digital vs. scanned documents  
ğŸ“¥ **REST API** - Complete API with upload, status polling, and download endpoints

---

## âš ï¸ Important Note

> **The application generates an Excel file for each job and serves it for download, but Excel files are not persisted permanently on the server.**
>
> âš¡ **Please download the Excel result immediately after the job completes.**
>
> The UI table is provided for visual inspection only and is not a stored copy of the Excel file.

---

## ğŸš€ Quick Start

### Prerequisites

- ğŸ Python 3.8 or higher
- ğŸ”‘ Mistral API key ([get one here](https://console.mistral.ai/))

### Installation

1ï¸âƒ£ **Clone the repository**

```bash
git clone https://github.com/wsmaisys/pdf-excel-extractor.git
cd pdf-excel-extractor
```

2ï¸âƒ£ **Create and activate a Python virtual environment**

**Windows (PowerShell):**

```powershell
python -m venv .venv
.\.venv\Scripts\Activate.ps1
```

**Linux/Mac:**

```bash
python -m venv .venv
source .venv/bin/activate
```

3ï¸âƒ£ **Install dependencies**

```bash
pip install -r requirements.txt
```

4ï¸âƒ£ **Configure environment variables**

```bash
cp .env.example .env
# Edit .env and add your MISTRAL_API_KEY
```

5ï¸âƒ£ **Run the server**

```bash
uvicorn app.main:app --reload --port 8000
```

6ï¸âƒ£ **Open the UI**

```
http://localhost:8000
```

Or use the live demo (Cloud Run):

```
https://pdf-excel-extractor-912303930048.us-central1.run.app/
```

---

## ğŸ“Š Workflow Diagram

```mermaid
flowchart TD
    A[ğŸ“„ Upload PDF] --> B[ğŸ” PDF Type Detection]
    B -- Digital --> C[ğŸ“ Text Extraction]
    B -- Scanned --> X[ğŸ›‘ Stop - OCR not supported]
    C --> D[ğŸ§  Dynamic Schema Detection LLM]
    D --> E[âš¡ Batch LLM Extraction - all keys]
    E --> F[ğŸ”„ Parse JSON â†’ DataFrame]
    F --> G["ğŸ“Š Export Excel - Key | Value | Comment"]
    E --> H[âœ… Evaluation: BLEU + Coverage]
    H --> I[ğŸ“ˆ Confidence Score]
    G --> J[â¬‡ï¸ Download Excel]
    I --> K[ğŸ–¥ï¸ UI Display - badge, logs, table]
```

---

## ğŸ—‚ï¸ Project Structure

```
pdf-excel-extractor/
â”‚
â”œâ”€â”€ ğŸ“ app/
â”‚   â””â”€â”€ main.py                    # ğŸš€ FastAPI server & job orchestration (entrypoint)
â”‚
â”œâ”€â”€ ğŸ“ pipeline/
â”‚   â”œâ”€â”€ schema_detector.py         # ğŸ§  LLM-based schema/key detection
â”‚   â”œâ”€â”€ llm_extractor.py          # âš¡ Builds batch prompt, calls LLM with retry/backoff
â”‚   â”œâ”€â”€ exporter.py               # ğŸ“Š Converts extraction JSON to pandas DataFrame & Excel
â”‚   â””â”€â”€ extract_kv.py             # ğŸ”§ Heuristic post-processing for key-value pairs
â”‚
â”œâ”€â”€ ğŸ“ tools/
â”‚   â””â”€â”€ pdf_detection.py          # ğŸ” Checks whether PDF is digital or scanned
â”‚
â”œâ”€â”€ ğŸ“ evaluation/
â”‚   â””â”€â”€ bleu_scorer.py            # ğŸ“ˆ BLEU score & coverage metrics for confidence
â”‚
â”œâ”€â”€ ğŸ“ static/
â”‚   â””â”€â”€ index.html                # ğŸ–¥ï¸ Web UI (upload, poll, render table, confidence badge)
â”‚
â”œâ”€â”€ ğŸ“„ pipeline_runner.py          # ğŸ”§ CLI runner for offline/batch execution
â”œâ”€â”€ ğŸ“„ requirements.txt            # ğŸ“¦ Python dependencies
â”œâ”€â”€ ğŸ“„ .env.example               # ğŸ”‘ Environment variables template
â”œâ”€â”€ ğŸ“„ Dockerfile                 # ğŸ³ Docker container configuration
â”œâ”€â”€ ğŸ“„ plan.md                    # ğŸ“ Project planning document
â””â”€â”€ ğŸ“„ API_DOCUMENTATION.md        # ğŸ“š Complete API reference with examples
```

---

## ğŸ“ File Descriptions

### ğŸ¯ Core Application

#### `app/main.py`

ğŸš€ **FastAPI Server & Job Orchestrator**

- Entry point for the application
- Manages job lifecycle and background tasks
- Handles file uploads and serves the web interface
- Coordinates all pipeline components

#### `static/index.html`

ğŸ–¥ï¸ **Web User Interface**

- Interactive upload interface
- Real-time job status polling
- Data table rendering
- Confidence score badge display
- Download management

---

### ğŸ”§ Pipeline Components

#### `pipeline/schema_detector.py`

ğŸ§  **Dynamic Schema Detection**

- Uses LLM to analyze PDF content
- Automatically identifies relevant data fields
- No hardcoded schemas required
- Adapts to different document types

#### `pipeline/llm_extractor.py`

âš¡ **Batch LLM Extraction Engine**

- Constructs optimized batch prompts
- Single LLM API call for efficiency
- Implements retry logic with exponential backoff
- Extracts all key-value pairs simultaneously

#### `pipeline/exporter.py`

ğŸ“Š **Data Export Module**

- Converts JSON extraction results to pandas DataFrame
- Generates Excel files with structured format
- Columns: Key | Value | Comment
- Handles data formatting and validation

#### `pipeline/extract_kv.py`

ğŸ”§ **Heuristic Post-Processor**

- Optional refinement of extracted data
- Pattern-based key-value pair detection
- Enhances LLM extraction accuracy
- Fallback extraction methods

---

### ğŸ› ï¸ Utility Tools

#### `tools/pdf_detection.py`

ğŸ” **PDF Type Classifier**

- Distinguishes between digital and scanned PDFs
- Prevents processing of OCR-required documents
- Fast pre-processing validation
- Saves API costs on incompatible files

---

### ğŸ“ˆ Evaluation System

#### `evaluation/bleu_scorer.py`

ğŸ“Š **Quality Assessment Module**

- Calculates BLEU scores for extraction accuracy
- Measures field coverage completeness
- Generates confidence scores (0-100%)
- Provides quality metrics for monitoring

---

### ğŸ”§ Additional Files

#### `pipeline_runner.py`

ğŸ–¥ï¸ **CLI Batch Runner**

- Command-line interface for offline processing
- Batch job execution without web server
- Useful for automation and testing
- Direct pipeline access

#### `requirements.txt`

ğŸ“¦ **Python Dependencies**

- FastAPI and Uvicorn (web framework)
- pandas, openpyxl (data processing)
- PyPDF2 or pdfplumber (PDF parsing)
- requests (HTTP client)
- python-dotenv (environment management)

#### `.env.example`

ğŸ”‘ **Environment Configuration Template**

- API key placeholders
- Server configuration defaults
- Copy to `.env` and customize

#### `Dockerfile`

ğŸ³ **Container Configuration**

- Production deployment setup
- Isolated environment
- Easy scaling and distribution

#### `plan.md`

ğŸ“ **Project Planning Document**

- Development roadmap
- Feature specifications
- Architecture decisions

#### `API_DOCUMENTATION.md`

ğŸ“š **Complete API Reference**

- Endpoint specifications
- Request/response schemas
- cURL examples
- Python requests snippets

---

## ğŸ”Œ API Endpoints

### ğŸ“¤ Upload PDF

```http
POST /upload
Content-Type: multipart/form-data
```

**Response:** `{ "job_id": "uuid" }`

### ğŸ“Š Check Status

```http
GET /status/{job_id}
```

**Response:** Job status, logs, extracted data, and evaluation results

### â¬‡ï¸ Download Excel

```http
GET /download/{job_id}
```

**Response:** Excel file download

> ğŸ’¡ See [API_DOCUMENTATION.md](API_DOCUMENTATION.md) for complete examples with cURL and Python requests

---

## ğŸ”„ Processing Pipeline

1. ğŸ“¤ **Upload PDF** via UI or `pipeline_runner.py`
2. ğŸ” **Type Detection** - `app/main.py` runs `tools/pdf_detection.py` (digital vs scanned)
3. ğŸ“ **Text Extraction** - Extract text if digital PDF
4. ğŸ§  **Schema Detection** - `pipeline/schema_detector.py` identifies relevant fields via LLM
5. âš¡ **Data Extraction** - `pipeline/llm_extractor.py` performs single batch LLM call
6. ğŸ”§ **Post-Processing** - Optional refinement with `pipeline/extract_kv.py`
7. ğŸ“ˆ **Evaluation** - `evaluation/bleu_scorer.py` calculates confidence metrics
8. ğŸ“Š **Export** - `pipeline/exporter.py` creates Excel file
9. â¬‡ï¸ **Download** - Serve via `/download/{job_id}` endpoint

---

## ğŸ¯ Use Cases

âœ… **Invoice Processing** - Extract vendor, amount, date, items  
âœ… **Resume Parsing** - Pull out skills, experience, education  
âœ… **Contract Analysis** - Identify parties, dates, terms  
âœ… **Report Mining** - Extract key metrics and findings  
âœ… **Form Digitization** - Convert filled forms to structured data

---

## ğŸš€ Deployment

### Docker Deployment

```bash
docker build -t pdf-excel-extractor .
docker run -p 8000:8000 --env-file .env pdf-excel-extractor
```

### Prebuilt Docker image (available on Docker Hub)

A prebuilt image has been pushed to Docker Hub so you can pull and run
without building locally. The image includes the LLM-enabled build.

```bash
# Pull the prebuilt image (LLM-enabled build)
docker pull wasimansariiitm/pdf-excel-extractor:llm

# Run the container and map port 8000 (reads .env for API keys)
docker run -p 8000:8000 --env-file .env wasimansariiitm/pdf-excel-extractor:llm
```

Available tags: `latest`, `pdf-extractor`, `pdf-to-excel`, `fastapi`, `mistral-ai`, `llm`.

### Production Considerations

- ğŸ” Add authentication/authorization
- ğŸ“Š Implement rate limiting
- ğŸ’¾ Add persistent storage for job history
- ğŸ”„ Set up background job queue (Celery/Redis)
- ğŸ“ˆ Add monitoring and logging (Prometheus/Grafana)

---

## ğŸ§ª Testing

### Run CLI Pipeline

```bash
python pipeline_runner.py --input sample.pdf --output results/
```

### API Testing

Use the examples in `API_DOCUMENTATION.md` with cURL or Python requests library.

---

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

---

## ğŸ“ License

This project is licensed under the MIT License - see the LICENSE file for details.

---

## ğŸ™ Acknowledgments

Created for **Turerz Sole Proprietorship**

- Powered by Mistral AI
- Built with FastAPI
- UI powered by vanilla JavaScript

---

## ğŸ“ Support

If you encounter any issues or have questions:

- ğŸ“§ Open an issue on GitHub
- ğŸ” Review existing issues for solutions

---

## ğŸ”® Future Enhancements

- [ ] OCR support for scanned documents
- [ ] Multi-language document support
- [ ] Batch file processing
- [ ] Custom schema templates
- [ ] Export to multiple formats (CSV, JSON, XML)
- [ ] Advanced visualization dashboard
- [ ] Machine learning model fine-tuning

---

**Made with â¤ï¸ and ğŸ¤– AI**
**Yours Truly, Waseem M Ansari**
